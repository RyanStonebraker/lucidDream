{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ryan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import gpt_2_simple as gpt2\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "import contextlib\n",
    "import re\n",
    "\n",
    "sys.path.append(\"../lib/InferSent\")\n",
    "from models import InferSent\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import spacy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18481(/19809) words with w2v vectors\n",
      "Vocab size : 18481\n"
     ]
    }
   ],
   "source": [
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048, 'pool_type': 'max', 'dpout_model': 0.0, 'version': 2}\n",
    "infersent = InferSent(params_model)\n",
    "infersent.load_state_dict(torch.load('../models/encoder/infersent2.pkl'))\n",
    "infersent.set_w2v_path(\"../models/fastText/crawl-300d-2M.vec\")\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "squad_df = pd.read_csv(\"../corpora/squad-dev-v2.0.csv\", index_col=0)\n",
    "\n",
    "sentences = []\n",
    "\n",
    "contexts = list(squad_df[\"contexts\"].drop_duplicates())\n",
    "for context in contexts:\n",
    "    doc = nlp(context)\n",
    "    sentences += [sentence.string.strip() for sentence in doc.sents]\n",
    "    \n",
    "infersent.build_vocab(sentences, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(text1, text2):\n",
    "    return np.dot(text1, text2)/(np.linalg.norm(text1) * np.linalg.norm(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(paragraph):\n",
    "    doc = nlp(paragraph)\n",
    "    return [sentence.string.strip() for sentence in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_predict(statements, question):\n",
    "    context_sentences = split_sentences(statements)\n",
    "    most_similar, highest_sim = \"\", 0\n",
    "    for sentence in context_sentences:\n",
    "        similarity = cosine_similarity(infersent.encode([question])[0], infersent.encode([sentence])[0])\n",
    "        if similarity > highest_sim:\n",
    "            most_similar = sentence\n",
    "            highest_sim = similarity\n",
    "    return most_similar, highest_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = {\"default\": {}}\n",
    "profile_dir = \"../corpora/profiles\"\n",
    "for profile in os.listdir(profile_dir):\n",
    "    df = pd.read_csv(f\"{profile_dir}/{profile}\")\n",
    "    character = df.columns.tolist()[0]\n",
    "    profiles[character] = {}\n",
    "    for emotion in df.columns.tolist()[1:]:\n",
    "        profiles[\"default\"][emotion] = 1 / len(df.columns.tolist()[1:])\n",
    "        profiles[character][emotion] = df[emotion].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotional_composite(emotional_profile, response_length):\n",
    "    composite_amount = random.randint(1,3)\n",
    "    emotions, probabilities = zip(*emotional_profile.items())\n",
    "    response_breakdown = [(str(emotion), math.floor(response_length/composite_amount) + int(i < response_length % composite_amount)) for i, emotion in enumerate(np.random.choice(emotions, composite_amount, p=probabilities))]\n",
    "    return response_breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_composite_response(sess, emotional_profile, conversation, character, response_length=30, scene=[]):\n",
    "    response = \"\\n\".join([f\"{sentence[0]}: {sentence[1]}\" for sentence in conversation]) + f\"\\nscene:{', '.join(scene)}\\n{character}:\"\n",
    "    start_offset = len(response)\n",
    "    response_breakdown = get_emotional_composite(emotional_profile, response_length)\n",
    "    for emotion, length in response_breakdown:\n",
    "        gpt2.reset_session(sess)\n",
    "        sess = gpt2.start_tf_sess()\n",
    "        gpt2.load_gpt2(sess, run_name=f\"{emotion}_run1\")\n",
    "        response = gpt2.generate(\n",
    "            sess,\n",
    "            length=length,\n",
    "            temperature=0.7,\n",
    "            prefix=response,\n",
    "            nsamples=1,\n",
    "            batch_size=1,\n",
    "            run_name=f\"{emotion}_run1\",\n",
    "            return_as_list=True\n",
    "        )[0]\n",
    "    return re.split(r\"[a-z A-Z0-9]+:\", response[start_offset:])[0].strip().split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_character_response(sess, profile, conversation, character, response_length=30, scene=[]):\n",
    "    seed = \"\\n\".join([f\"{sentence[0]}: {sentence[1]}\" for sentence in conversation]) + f\"\\nscene:{', '.join(scene)}\\n{character}:\"\n",
    "    gpt2.reset_session(sess)\n",
    "    sess = gpt2.start_tf_sess()\n",
    "    gpt2.load_gpt2(sess, run_name=f\"{character}_run1\")\n",
    "    response = gpt2.generate(\n",
    "        sess,\n",
    "        length=response_length,\n",
    "        temperature=0.7,\n",
    "        prefix=seed,\n",
    "        nsamples=1,\n",
    "        batch_size=1,\n",
    "        run_name=f\"{character}_run1\",\n",
    "        return_as_list=True\n",
    "    )[0][len(seed):]\n",
    "    return re.split(r\"[a-z A-Z0-9]+:\", response)[0].strip().split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_holistic_model_response(sess, profile, conversation, character, response_length=30, scene=[]):\n",
    "    seed = \"\\n\".join([f\"{sentence[0]}: {sentence[1]}\" for sentence in conversation]) + f\"\\nscene:{', '.join(scene)}\\n{character}:\"\n",
    "    gpt2.reset_session(sess)\n",
    "    sess = gpt2.start_tf_sess()\n",
    "    gpt2.load_gpt2(sess, run_name=f\"full_model_run1\")\n",
    "    response = gpt2.generate(\n",
    "        sess,\n",
    "        length=response_length,\n",
    "        temperature=0.7,\n",
    "        prefix=seed,\n",
    "        nsamples=1,\n",
    "        batch_size=1,\n",
    "        run_name=f\"full_model_run1\",\n",
    "        return_as_list=True\n",
    "    )[0][len(seed):]\n",
    "    return re.split(r\"[a-z A-Z0-9]+:\", response)[0].strip().split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_conversation(\n",
    "    conversation=[], \n",
    "    scene=[\"harry\", \"user\", \"environment\"], \n",
    "    characters=[\"harry\", \"ron\", \"hermione\", \"snape\", \"albus dumbledore\", \"tom riddle\", \"hagrid\", \"user\", \"environment\"],\n",
    "    character_addition_prob=0.2,\n",
    "    character_removal_prob=0.25,\n",
    "    env_model=generate_character_response, \n",
    "    char_model=generate_composite_response, \n",
    "    length=10,\n",
    "    print_scene=False,\n",
    "    profiles=profiles,\n",
    "    end_on_empty=True,\n",
    "    write_to_file=False,\n",
    "    file_name=\"conversation.txt\"\n",
    "):\n",
    "    print(\"Scene:\")\n",
    "    [print(f\"\\t{character}: {statement}\") for character, statement in conversation]\n",
    "    print(\"\")\n",
    "    sess = gpt2.start_tf_sess()\n",
    "    with open(f\"output/{file_name}\", \"w\", buffering=1) as output_writer:\n",
    "        [output_writer.write(f\"\\t{character}: {statement}\") for character, statement in conversation]\n",
    "        for i in range(length):\n",
    "            if i and random.random() < character_removal_prob:\n",
    "                del scene[scene.index(random.choice(scene))]\n",
    "            if i and random.random() < character_addition_prob:\n",
    "                scene.append(random.choice([character for character in characters if character not in scene]))\n",
    "            if not scene:\n",
    "                if end_on_empty:\n",
    "                    break\n",
    "                else:\n",
    "                    scene = [random.choice(characters)]\n",
    "            with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "                character = random.choice([character for character in scene if len(scene) < 2 or not conversation or character != conversation[-1][0]])\n",
    "                if character == \"user\":\n",
    "                    print(\"user: \", end=\"\")\n",
    "                    response = input(\"user: \")\n",
    "                elif character == \"environment\":\n",
    "                    response = env_model(sess, profiles[character] if character in profiles else profiles[\"default\"], conversation[-30:], \"environment\", scene=scene)\n",
    "                else:\n",
    "                    response = char_model(sess, profiles[character] if character in profiles else profiles[\"default\"], conversation[-30:], character, scene=scene)\n",
    "            if character != \"user\":\n",
    "                print(f\"{character.capitalize()}: {response}{' - ' + str(scene) if print_scene else ''}\")\n",
    "            conversation.append((character, response))\n",
    "            if write_to_file:\n",
    "                output_writer.write(f\"{character.capitalize()}: {response}\\n\")\n",
    "            if len(conversation) > 5:\n",
    "                predicted_response, _ = cosine_predict(\"\\n\".join([statement for _, statement in conversation[:-1]]), response)\n",
    "                conversation.append((character, predicted_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = [\n",
    "    (\"environment\", \"Diagon Alley was completely empty because of the coronavirus.\"),\n",
    "    (\"hagrid\", \"Where is everybody?\"),\n",
    "    (\"albus dumbledore\", \"Hopefully at home.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene:\n",
      "\tenvironment: Diagon Alley was completely empty because of the coronavirus.\n",
      "\thagrid: Where is everybody?\n",
      "\talbus dumbledore: Hopefully at home.\n",
      "\n",
      "Environment: Harry washes his face with a towel. - ['harry', 'ron', 'hermione', 'harry_as_voldemort', 'environment']\n",
      "Hermione: There's no sign of them. There's just... silence. - ['harry', 'ron', 'hermione', 'harry_as_voldemort', 'environment']\n",
      "Environment: They were walking through fog and shadows. - ['harry', 'ron', 'hermione', 'harry_as_voldemort', 'environment']\n",
      "Harry: We've been roundly bitten, haven't we? - ['harry', 'ron', 'hermione', 'environment']\n",
      "Environment: They stop as they see someone walking around the corner. - ['harry', 'ron', 'hermione', 'environment', 'hagrid']\n",
      "Harry: That's not good. - ['harry', 'ron', 'hermione', 'environment', 'hagrid']\n",
      "Ron: That's not good. I can't believe they're going to kill harry. - ['harry', 'ron', 'hermione', 'hagrid']\n",
      "Harry: That's not good. I can't believe they're going to kill harry. - ['harry', 'hermione', 'hagrid']\n",
      "Hagrid: Round up the rats. Sack them into the Priory. - ['harry', 'hermione', 'hagrid']\n",
      "Hermione: There's something the both of you need to see. - ['harry', 'hermione', 'hagrid', 'albus dumbledore']\n",
      "Harry: Look. The monster of the year is dead. Sirius Black has been killed. - ['harry', 'hermione', 'hagrid', 'albus dumbledore']\n",
      "Albus dumbledore: It was a despicable crime, Hagrid. It was a despicable crime to kill Sirius Black. - ['harry', 'hermione', 'hagrid', 'albus dumbledore']\n",
      "Hagrid: You'd better clear out. There's some sort of attack going on in the castle. - ['harry', 'hermione', 'hagrid', 'albus dumbledore']\n",
      "Hermione: (taking harry's arm) Come on. Run. You're wasting time. - ['harry', 'hermione', 'hagrid', 'albus dumbledore']\n",
      "Albus dumbledore: Headmaster, we've received intelligence that a group is preparing to attack the castle. - ['harry', 'hermione', 'hagrid', 'albus dumbledore']\n",
      "Hagrid: That's not good. - ['harry', 'hermione', 'hagrid', 'albus dumbledore']\n",
      "Environment: They approach a flat ground with gnarled roots all over. - ['harry', 'hermione', 'hagrid', 'albus dumbledore', 'environment']\n",
      "Harry: The group walks along a path to a castle. - ['harry', 'hermione', 'hagrid', 'albus dumbledore', 'environment']\n",
      "Albus dumbledore: There's an attack going on in the castle. - ['harry', 'hermione', 'hagrid', 'albus dumbledore', 'environment']\n",
      "Hermione: There's something the both of you need to see. - ['harry', 'hermione', 'hagrid', 'albus dumbledore', 'environment']\n",
      "Albus dumbledore: There's an attack going on in the castle. - ['harry', 'hermione', 'hagrid', 'albus dumbledore', 'environment']\n",
      "Hermione: (rising from her bedroom) I've got to go. I've got to find my dad. - ['harry', 'hermione', 'hagrid', 'albus dumbledore', 'environment']\n",
      "Hagrid: Breakfast, Hagrid. - ['harry', 'hermione', 'hagrid', 'albus dumbledore', 'environment']\n",
      "Environment: dumbledore is leading the group to a balcony overlooking the common room, where a cloaked man is standing next to a tree. - ['harry', 'hermione', 'hagrid', 'albus dumbledore', 'environment', 'snape']\n",
      "Snape: There is an attack going on in the castle. - ['harry', 'hermione', 'hagrid', 'albus dumbledore', 'environment', 'snape']\n",
      "Hermione: I can't believe they're actually going to attack the castle. It's too far gone. - ['harry', 'hermione', 'hagrid', 'environment', 'snape']\n",
      "Environment: breakfast. breakfast. - ['harry', 'hermione', 'hagrid', 'environment', 'snape']\n",
      "Hermione: Professor, what exactly does the basilisk do? - ['hermione', 'hagrid', 'environment', 'snape']\n",
      "Snape: Everyone is to stay inside. There's an attack coming. - ['hermione', 'hagrid', 'environment', 'snape']\n",
      "Environment: dumbledore and hermione are walking through the garden, talking. - ['hermione', 'hagrid', 'environment', 'snape']\n",
      "Hermione: Everyone's to stay inside. There's an attack coming. - ['hermione', 'hagrid', 'environment', 'snape']\n",
      "Snape: Everyone's to stay inside. There's an attack coming. - ['hermione', 'hagrid', 'environment', 'snape']\n",
      "Harry: Everyone's to stay inside. There's an attack coming. - ['hermione', 'hagrid', 'environment', 'snape', 'harry']\n",
      "Hagrid: Everyone's to stay inside. There's an attack coming. - ['hermione', 'hagrid', 'environment', 'snape', 'harry']\n",
      "Hermione: Everyone's to stay inside. There's an attack coming. - ['hermione', 'hagrid', 'environment', 'snape', 'harry']\n",
      "Hagrid: Everyone's to stay inside. There's an attack coming. - ['hermione', 'hagrid', 'environment', 'snape', 'harry']\n",
      "Hermione: Come on, Harry. - ['hermione', 'hagrid', 'environment', 'snape']\n",
      "Hagrid: Breakfast, Hagrid. - ['hermione', 'hagrid', 'snape']\n",
      "Hermione: I've got a few questions for Hagrid. - ['hermione', 'hagrid', 'snape']\n",
      "Snape: You go back to the owls. I want to know what you're doing. - ['hermione', 'hagrid', 'snape']\n",
      "Albus dumbledore: You go back to the owls. - ['hermione', 'hagrid', 'snape', 'albus dumbledore']\n",
      "Hagrid: I've got news for you, Miss Granger. You're wasting time. Go on. Go on. - ['hermione', 'hagrid', 'albus dumbledore']\n",
      "Albus dumbledore: Excellent. - ['hermione', 'hagrid', 'albus dumbledore']\n",
      "Hagrid: I've got to find my dad. - ['hermione', 'hagrid', 'albus dumbledore']\n",
      "Hermione: I can't believe I'm meeting this guy. - ['hermione', 'albus dumbledore', 'harry_as_voldemort']\n",
      "Albus dumbledore: Very well. Then I shall kill him. - ['hermione', 'albus dumbledore', 'harry_as_voldemort']\n",
      "Harry_as_voldemort: Severus... I had you looked into it. There is much I would like to learn... - ['hermione', 'albus dumbledore', 'harry_as_voldemort']\n",
      "Albus dumbledore: What are you looking at? {Harry looks at a drawing of a bull with a snake entwined around its head.} - ['hermione', 'albus dumbledore', 'harry_as_voldemort']\n",
      "Harry_as_voldemort: I've got something of yours. Harry_has_something_of_sorts.com - ['albus dumbledore', 'harry_as_voldemort']\n",
      "Albus dumbledore: Yes, Harry? - ['albus dumbledore', 'harry_as_voldemort', 'harry']\n",
      "Harry: Everyone's fine. - ['albus dumbledore', 'harry_as_voldemort', 'harry']\n",
      "Albus dumbledore: About time too. I've been looking a bit... nervous. - ['albus dumbledore', 'harry_as_voldemort', 'harry']\n",
      "Harry: What are those? - ['albus dumbledore', 'harry_as_voldemort', 'harry', 'environment']\n",
      "Albus dumbledore: I have a few... questions for... Hagrid. - ['albus dumbledore', 'harry_as_voldemort', 'harry', 'environment']\n",
      "Harry: I've got a few... questions for... Hagrid. - ['albus dumbledore', 'harry_as_voldemort', 'harry', 'environment', 'tom riddle']\n",
      "Harry_as_voldemort: You must be Tom Riddle. - ['albus dumbledore', 'harry_as_voldemort', 'harry', 'environment', 'tom riddle']\n",
      "Tom riddle: Professor Dumbledore. - ['albus dumbledore', 'harry_as_voldemort', 'harry', 'environment', 'tom riddle']\n",
      "Harry_as_voldemort: You must be Tom Riddle. - ['albus dumbledore', 'harry_as_voldemort', 'harry', 'environment', 'tom riddle']\n",
      "Environment: hagrid and others are in the hall. - ['albus dumbledore', 'harry_as_voldemort', 'harry', 'environment', 'tom riddle']\n"
     ]
    }
   ],
   "source": [
    "start_conversation(\n",
    "    conversation=scene, \n",
    "    scene=[\"harry\", \"ron\", \"hermione\", \"harry_as_voldemort\", \"environment\"], \n",
    "    characters=[\"harry\", \"ron\", \"hermione\", \"snape\", \"albus dumbledore\", \"tom riddle\", \"hagrid\", \"harry_as_voldemort\", \"environment\"],\n",
    "    character_addition_prob=0.2,\n",
    "    character_removal_prob=0.15,\n",
    "    env_model=generate_holistic_model_response, \n",
    "    char_model=generate_holistic_model_response, \n",
    "    length=200,\n",
    "    print_scene=True,\n",
    "    profiles=profiles,\n",
    "    end_on_empty=False,\n",
    "    write_to_file=True,\n",
    "    file_name=\"conversation_200.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = [\n",
    "    (\"environment\", \"Diagon Alley was completely empty because of the coronavirus.\"),\n",
    "    (\"hagrid\", \"Where is everybody?\"),\n",
    "    (\"albus dumbledore\", \"Hopefully at home.\"),\n",
    "]\n",
    "\n",
    "start_conversation(\n",
    "    conversation=scene, \n",
    "    scene=[\"harry\", \"ron\", \"hermione\", \"hagrid\", \"albus dumbledore\", \"environment\"], \n",
    "    characters=[\"harry\", \"ron\", \"hermione\", \"snape\", \"albus dumbledore\", \"tom riddle\", \"hagrid\", \"harry_as_voldemort\", \"environment\"],\n",
    "    character_addition_prob=0.21,\n",
    "    character_removal_prob=0.15,\n",
    "    env_model=generate_holistic_model_response, \n",
    "    char_model=generate_character_response, \n",
    "    length=200,\n",
    "    print_scene=True,\n",
    "    profiles=profiles,\n",
    "    end_on_empty=False,\n",
    "    write_to_file=True,\n",
    "    file_name=\"conversation_200_single_char.txt\"\n",
    ")\n",
    "\n",
    "with open(\"output/conversation_200_single_char_full_debug.txt\", \"w\") as debug_writer:\n",
    "    for speaker, statement in scene:\n",
    "        debug_writer.write(f\"{speaker}: {statement}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(content):\n",
    "    content = content.lower().strip()\n",
    "    content = re.sub(r\"[^a-zA-Z]\", \" \", str(content))\n",
    "    content = re.sub(r\"[\\s\\t\\n]+\", \" \", content)\n",
    "    tokens = [word for word in content.split() if word and word not in stopwords.words(\"english\")]\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "isear_df = pd.read_csv(\"../corpora/isear.csv\", header=None)\n",
    "isear_df.columns = [\"emotion\", \"text\", \"\"]\n",
    "isear_df = isear_df.drop([\"\"], axis=1)\n",
    "cleaned_text = [clean_text(text) for text in isear_df[\"text\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "training_counts = count_vectorizer.fit_transform(cleaned_text)\n",
    "bag_of_words = count_vectorizer.transform(cleaned_text)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(bag_of_words)\n",
    "log_regression = Pipeline([\n",
    "        ('vect', count_vectorizer), \n",
    "        ('tfidf', tfidf_transformer),\n",
    "        ('clf', SGDClassifier(loss=\"log\", \n",
    "                              penalty='l1',\n",
    "                              random_state=1\n",
    "                             ))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_probs(classifier, data):\n",
    "    prob_spread = classifier.predict_proba([data]).tolist()[0] if hasattr(classifier, \"predict_proba\") else None\n",
    "    probabilities = pd.DataFrame({\"class\": classifier.classes_, \"probability\": prob_spread})\n",
    "    probabilities = probabilities.sort_values(by=\"probability\", ascending=False)\n",
    "    probabilities = probabilities.set_index(\"class\").T.reset_index()\n",
    "    del probabilities[\"index\"]\n",
    "    probabilities[\"predicted\"] = log_regression.predict([data])\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_df = pd.read_csv(\"output/conversation_200.txt\", sep=\": \", columns=[\"character\", \"statement\"])\n",
    "generated_character_profiles = {}\n",
    "for character in [\"harry\", \"ron\", \"hermione\", \"snape\", \"albus dumbledore\", \"tom riddle\", \"hagrid\", \"harry_as_voldemort\"]:\n",
    "    emotion_breakdown = pd.concat([get_class_probs(log_regression, row.statement) for i, row in scene_df[scene_df.character == character].iterrows()], sort=False)\n",
    "    generated_character_profiles[character] = pd.DataFrame(emotion_breakdown.mean()).T\n",
    "    generated_character_profiles[character].index.name = character\n",
    "    generated_character_profiles[character] = generated_character_profiles[character].T.rename(columns={0:\"percent\"}).sort_values(by=\"percent\", ascending=False)\n",
    "display_dataframes_inline(*[df for _, df in character_profiles.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_profiles = {}\n",
    "profile_dir = \"../corpora/profiles\"\n",
    "for profile in os.listdir(profile_dir):\n",
    "    expected_profiles[profile[:-4]] = pd.read_csv(f\"{profile_dir}/{profile}\")\n",
    "display_dataframes_inline(*[df for _, df in character_profiles.items()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
